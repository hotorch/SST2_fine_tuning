{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SST2 data with huggingface transformer(remark version).ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hotorch/SST2_fine_tuning/blob/master/SST2_data_with_huggingface_transformer(remark_version).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17vI_MOjz3uW",
        "colab_type": "text"
      },
      "source": [
        "## huggingface transformers "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYMz3k97WvPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlHMn2Dax930",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel, BertTokenizer # load language model & tokenizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9WLP-bnyg1W",
        "colab_type": "text"
      },
      "source": [
        "huggingface에서 https://huggingface.co/transformers/model_doc/bert.html 를 참조"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgqjgavWyNTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJy7-8sIy7ZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizer test\n",
        "text = 'The BERT model was proposed in BERT'\n",
        "\n",
        "print(tokenizer(text))\n",
        "\n",
        "len(tokenizer(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXPDmJdqzAuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode -> list type\n",
        "# encode 함수에 스페셜 토큰을 보고 싶지 않을 때에는 add_special_tokens = False 활용\n",
        "tokenizer.encode(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE94ygh3zK4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decode\n",
        "tokenizer.decode(tokenizer.encode(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxYZXeWL0McD",
        "colab_type": "text"
      },
      "source": [
        "#### 조금 더 살펴보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS6k8MUHzl0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = tokenizer.encode(text)\n",
        "input_ids_tensor = torch.tensor(input_ids, dtype = torch.long).unsqueeze(0).cuda()\n",
        "bert = BertModel.from_pretrained('bert-base-uncased').cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQvSf1Vr33ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = bert(input_ids_tensor)\n",
        "embeddings[0]\n",
        "print(embeddings[0].shape) # |batch_size, # of tokens, bert dimension|"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3txfUU388ufI",
        "colab_type": "text"
      },
      "source": [
        "#### Load Data(SST-2)\n",
        "\n",
        "https://nlp.stanford.edu/sentiment/index.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhTX6WqM9QjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zebDF1DP96e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"drive/My Drive/SST-2/\"\n",
        "os.listdir(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HJ1s_uU9US3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(path + 'train.tsv', delimiter = '\\t')[:1000] # 일부분만 활용\n",
        "# dev = pd.read_csv('dev.tsv', delimiter = '\\t')\n",
        "# test = pd.read_csv('test.tsv', delimiter = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIFnYmAW-cc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 문장 길이가 다르기 때문에 [PAD] token을 활용해야함, 또한 최대 길이도 정해야함\n",
        "print(train['sentence'].apply(lambda x: tokenizer.encode(x))[0])\n",
        "print(train['sentence'].apply(lambda x: tokenizer.encode(x))[1]) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfqnKrXk_wc3",
        "colab_type": "text"
      },
      "source": [
        "#### Define Max Length & fix dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRjAznvK_eAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = train['sentence'].apply(lambda x: len(x)).max() # 250\n",
        "train['sentence'] = train['sentence'].apply(lambda x: tokenizer.encode(x))\n",
        "# insert [pad]\n",
        "padded_ids = np.array([sentence + [0] * (MAX_LEN - len(sentence)) \n",
        "\t\t\t\t\t   for sentence in train['sentence']])\n",
        "print(padded_ids.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTLa12XZECtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 필요한 문장만을 활용하기 위해 attention mask 활용\n",
        "attention_mask = np.where(np.array(padded_ids) != 0, 1, 0)\n",
        "# tensor로 변환하기 \n",
        "padded_ids_tensor = torch.tensor(padded_ids, dtype=torch.long)\n",
        "attention_mask_tensor = torch.tensor(attention_mask, dtype= torch.long)\n",
        "output_tensor = torch.tensor(train[['label']].values, dtype = torch.long) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXBDWBJOFDyj",
        "colab_type": "text"
      },
      "source": [
        "#### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZirbLn3FHUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.linear = nn.Linear(768, 2)\n",
        "\n",
        "        for parameter in self.bert.parameters():\n",
        "            parameter.requires_grad = False # bert안에 있는 parameter 건드리지 않기, 오로지 nn.linear만 학습\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids dimension : |batch_size, MAX_LEN, embedding_dim|\n",
        "        input_ids = self.bert(input_ids, attention_mask= attention_mask)[0]\n",
        "        # ouput dimension : |batch_size, MAX_LEN, embedding_dim|\n",
        "        input_ids = input_ids[:,0,:]\n",
        "        return self.linear(input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odZf1PaOHCQk",
        "colab_type": "text"
      },
      "source": [
        "#### Define DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0CXHjKEGbgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "# 데이터 길이, 데이터 인덱스 던져줬을 때 어떤 것을 리턴할지만 고려하기\n",
        "\n",
        "class SST2(Dataset):\n",
        "    def __init__(self, \n",
        "               input_ids,\n",
        "               attention_mask,\n",
        "               output):\n",
        "        super().__init__()\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.output = output\n",
        "  \n",
        "    def __len__(self): \n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.input_ids[index], self.attention_mask[index], self.output[index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2m3VO53FG3Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = SentimentClassifier().cuda()\n",
        "optimizer = optim.SGD(net.parameters(), lr = 0.001)\n",
        "loss_fn = nn.CrossEntropyLoss().cuda()\n",
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLO1kDdOHSea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = SST2(padded_ids_tensor[:700],\n",
        "                     attention_mask_tensor[:700],\n",
        "                     output_tensor[:700])\n",
        "\n",
        "valid_dataset = SST2(padded_ids_tensor[700:],\n",
        "                     attention_mask_tensor[700:],\n",
        "                     output_tensor[700:])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ciNwwZIeAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 25분 정도 소요, accuracy 53%\n",
        "import tqdm\n",
        "\n",
        "for epoch in tqdm.tqdm_notebook(range(EPOCHS)):\n",
        "\tfor input_ids, attention_mask, output in tqdm.tqdm_notebook(train_dataloader):\n",
        "\t\tpredictions = net(input_ids.cuda(), attention_mask.cuda())\n",
        "\t\tloss = loss_fn(predictions, output.cuda().squeeze())\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\tnum_correct = 0\n",
        "\t\tfor input_ids, attention_mask, output in tqdm.tqdm_notebook(valid_dataloader):\n",
        "\t\t\tpredictions = net(input_ids.cuda(), attention_mask.cuda())\n",
        "\t\t\tloss = loss_fn(predictions, output.cuda().squeeze())\n",
        "\n",
        "\t\t\tnum_correct += (predictions.max(dim=1)[1] == output.cuda().squeeze()).sum().item()\n",
        "\n",
        "\t\taccuracy = num_correct / len(valid_dataloader) * 8\n",
        "\n",
        "\t\tprint(accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU50bQggKvCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}